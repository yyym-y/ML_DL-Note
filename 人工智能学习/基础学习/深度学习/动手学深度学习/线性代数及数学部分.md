**向量**
 $\displaystyle{||\mathbf{a||_1} = \left[ \sum_{i=1}^{m} |a_i| \right]}$ $\displaystyle{||\mathbf{a}||_2 = \left[ \sum_{i=1}^{m} a_i^{2} \right]^{\frac{1}{2}}}$ 
点乘： $\displaystyle{a \cdot b = \sum a_ib_i }$ , $\displaystyle{\mathbf{a \cdot b = 0 }}$ 说明两个向量垂直

**矩阵**
矩阵的乘法
> 矩阵乘向量 : $\displaystyle{M_{n \times m} \times V_{m}}$![[Screenshot_2025-05-02-21-52-50-747_com.jideos.jnotes.png]]
> 矩阵乘矩阵 ： $\displaystyle{A_{n\times m} \times B_{m \times u} = C_{m \times u}}$
> ![[Screenshot_2025-05-02-21-59-54-570_com.jideos.jnotes.png]]

矩阵的范数 $\displaystyle{\text{Frobenius}}$ 范数 ： $\displaystyle{||\mathbf{A}||_{\text{Frob}} = \left[ \sum_{ij} \mathbf{A_{ij}^{2}} \right]^{\frac{1}{2}}}$ 
特殊矩阵
> 对称和反对称 ： $\displaystyle{A_{ij} = A_{ji}}$ 关于对角线对称， $\displaystyle{A_{ij} = - A_{ji}}$ 反对称
> 正定矩阵： 这个矩阵乘上任何一个列向量或者行向量都大于等于 $\displaystyle{0}$ 
> 正交矩阵 ： 
> > 所有行都相互正交
> > 所有行都有单位长度
> 
> 置换矩阵 ：...

特征向量和特征值 $\displaystyle{Ax = \lambda x}$
> 我们说矩阵相乘是对空间的扭曲，特征向量是不改变方向的
> 对称矩阵总可以找到特征向量


### 矩阵运算的实现

```python

import torch

A = torch.arange(20).reshape(4,5)

# 矩阵的逆
print(A.T)
# 判断是否为对称矩阵, 全为 True 就是， 主要必须是方阵
B = torch.arange(16).reshape(4,4)
print(B == B.T)
# 内存分配
C = torch.arange(16).reshape(4,4)
D = C
D[1,1] = 0
print(D == C) # 完全相同
E = C.clone()
E[1,1] = 100
print(E == C) # 有一个不同
# 哈达玛积（每个元素依次相乘）
A = torch.arange(16).reshape(4,4)
B = torch.arange(16).reshape(4,4)
print(A * B)
A = torch.arange(60).reshape(3,4,5)
print(A)
print(A.shape, A.sum())
sum_1 = A.sum(axis=0)
print(sum_1.shape, sum_1)
# 多个纬度求和，用压缩理解
print(A.sum(axis=[0,1]).shape, A.sum(axis=[0,2]).shape)
# 均值(元素必须是浮点数)
A = torch.arange(60, dtype=torch.float32).reshape(3,4,5)
print(A.mean(), A.sum() / A.numel())
# 向量的点乘
x, y = torch.arange(5),torch.arange(5)
print(torch.dot(x,y))
# 矩阵乘向量
A = torch.arange(20).reshape(4,5)
print(A.shape, x.shape, torch.mv(A, x))
# 矩阵乘矩阵
B = torch.arange(20).reshape(5,4)
print(A.shape, B.shape, torch.mm(A, B))
# L2 范数
x = torch.arange(5, dtype=torch.float32)
print(torch.norm(x))
# L1 范数
print(torch.abs(x).sum())
# 矩阵的 F 范数
A = torch.arange(20, dtype=torch.float32).reshape(4,5)
print(torch.norm(torch.ones(4,5)))
# 求和的时候保留纬度，会吧求和的那个纬度的shape变成1
A = torch.ones((2,5,4))
tem = A.sum(axis=1, keepdims=True)
print(A, A.shape)
print(tem, tem.shape)
```

